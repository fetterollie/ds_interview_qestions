{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the assumptions of linear regressions?\n",
    "- Linear Relationship\n",
    "- Independence\n",
    "- Normal Distribution\n",
    "- Homeskedacity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to test for collinearity?\n",
    "- Pearson Correlation : coefficients of .7 or higher indicitave of strong correlation\n",
    "    looks at degree of multicollinearity a pair\n",
    "- Variance Inflation Factor : looks at individual point, value of 10 or higher indicates strong correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you test for homo or hetero skedasticity?\n",
    "- visual inspection looking for variance of amplitude of error : looking for consistent amplitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain about TypeI error:\n",
    "- Rejecting null hypothesis when (it's actually true) you should have failed to reject the null.\n",
    "\n",
    "Explain about TypeII error: \n",
    "- Fail to reject the null hypothesis (it's actually false) when you should have rejected the null-hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me about a confusion matrix (binary): \n",
    " - plot in quadrants\n",
    " - predicted values on y-axis\n",
    " - actual values on x-axis\n",
    " - TN, FP\n",
    " - FN, TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC/AUC Curve: \n",
    "- ROC: Receiver Operating Characteristic\n",
    "- AUC: Area Under (the) Curve\n",
    "- Tells you how much the model is capable of distinguishing between classes\n",
    "- This plots 'True Positive Rate' against the 'False Positive Rate'\n",
    "- The higher the AUC (closer to 1) the better\n",
    "- A graph of a good ROC/AUC should hug the top left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a p-value?\n",
    "- a measure of significance of the regression coefficients\n",
    "- If p-value is below a _chosen_ significance level (_typically 0.05_), then the null-hypothesis **is rejected**; the predictor **is related** to the outcome\n",
    "- helps determine which predictors should be included in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I interpret the coefficient of linear regression?\n",
    "- **Linear Regression:** A 1 unit increase of the predictor, results in this much increase in the target\n",
    "- **Multiple Linear Regression:** All else held equal, a 1 unit increase in the predictor results in this much increase in the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||**This question could use editing**|||\n",
    "\n",
    "How do I know if my linear regression is over fit?\n",
    "- R^2 == 1\n",
    "- cross-val\n",
    "How to fix an over fit linear regression model?\n",
    "- Regularizations (L1 & L2)\n",
    "L1 - Lasso\n",
    "- Absolute Value\n",
    "L2 - Ridge\n",
    "- Square the error term\n",
    "Elastic Net\n",
    "- Combination of L1 and L2\n",
    "PCA\n",
    "Add More Data\n",
    "- could find a signal\n",
    "Feature Engineering\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to know if feature is statistically significant to the model?\n",
    "- p-value\n",
    "- if p-value for each feature is less than the *chosen* alpha, you can use that feature\n",
    "- it means that the feature has signal in it (**is statistically significant**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is scaling important to models like KNN, linear regression, PCA etc?\n",
    "- they are distance based algorithms\n",
    "- helps to bring all the features  to the same magnitude\n",
    "- **Without scaling** features with large values will have a greater impact on the distance calculation which translates to the model's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigen Vector vs Eigen Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes - What is the Naive part?\n",
    "- probability of each event is unrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When do you use median over mean?\n",
    "- Outliers\n",
    "- any data points that would pull the mean\n",
    "- skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering & KNN how they work?\n",
    "- tell the algorithm how many clusters (k)\n",
    "- what's the biggest diff: KNN is supervised and k-means clustering is unsupervised\n",
    "- supervised you need a target to predict, unsupervised will create classes\n",
    "- silhouette score: needs explanation\n",
    "- inertia: needs explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a Decision Tree?\n",
    "- recursive\n",
    "\n",
    "How does it determine that value?\n",
    "- Gini score\n",
    "- Entropy\n",
    "\n",
    "What is a strength of Decision Trees?\n",
    "- Can take all types of data once categoricals are encoded\n",
    "Weakness?\n",
    "- Does not handle imbalances of data well\n",
    "- Prone to overfitting\n",
    "\n",
    "Which Type of algorithm is used at each split point?\n",
    "- Greedy Algo used at each split point in decision tree\n",
    "\n",
    "There are 3 levels of randomness:\n",
    "Levels of randomness:\n",
    "- Bagging - bootstrap sample of data\n",
    "- Random Forests - bootstrap sample of data AND features\n",
    "- ExtraTrees - all the above with a random split point (versus using Gini or Entropy)\n",
    "\n",
    "How to show relative importance of features in model.\n",
    "- Feature Importance Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain Skew and Kurtosis: \n",
    "- Skew: \n",
    "- When you have a right tailed distribution, where does the mean fall in relation to the medianB\n",
    "Skew Normal == 0\n",
    "Kurtosis == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is A/B TESTING:\n",
    "\n",
    "adjusting parameters to see the difference?\n",
    "    \n",
    "z-test\n",
    "    \n",
    "t-test\n",
    "\n",
    "- 1 tail\n",
    "- 2 tail\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Coefficient\n",
    "- a 1 unit increase in coefficient translatesb\n",
    "\n",
    "What is a type I and type II error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does gradient descent converge to the same point?\n",
    "- could be local min or global min depends on (function?)\n",
    "Trying to find min of loss function\n",
    "How do you know?\n",
    "gd takes partial derivative at point - am i close to 0? y/n? keep going, try again...\n",
    "What happens if learning rate is too low or too high?\n",
    "- too high might miss global minimum\n",
    "- too low might not converge on minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a confustion matrix tell us?\n",
    "- plots predictions vs outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CodingBat Code Practice](https://codingbat.com/prob/p173401)\n",
    "\n",
    "The parameter weekday is True if it is a weekday, and the parameter vacation is True if we are on vacation. We sleep in if it is not a weekday or we're on vacation. Return True if we sleep in.\n",
    "- sleep_in(False, False) → True\n",
    "- sleep_in(True, False) → False\n",
    "- sleep_in(False, True) → True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many ways to solve this.\n",
    "def sleep_in(weekday, vacation):\n",
    "  if not weekday or vacation:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CodingBat Code Practice](https://codingbat.com/prob/p149524)\n",
    "\n",
    "Given a non-empty string and an int n, return a new string where the char at index n has been removed. The value of n will be a valid index of a char in the original string (i.e. n will be in the range 0..len(str)-1 inclusive).\n",
    "- missing_char('kitten', 1) → 'ktten'\n",
    "- missing_char('kitten', 0) → 'itten'\n",
    "- missing_char('kitten', 4) → 'kittn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many ways to solve this.\n",
    "def missing_char(str, n):\n",
    "  return str[:n] + str[n+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_char(str, n):\n",
    "  front = str[:n]   # up to but not including n\n",
    "  back = str[n+1:]  # n+1 through end of string\n",
    "  return front + back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CodingBat Code Practice](https://codingbat.com/prob/p197466)\n",
    "\n",
    "Given an int n, return the absolute difference between n and 21, except return double the absolute difference if n is over 21.\n",
    "\n",
    "\n",
    "- iff21(19) → 2\n",
    "- diff21(10) → 11\n",
    "- diff21(21) → 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff21(n):\n",
    "  if n > 21:\n",
    "    return 2 * abs(n-21)\n",
    "  else:\n",
    "    return abs(n-21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
